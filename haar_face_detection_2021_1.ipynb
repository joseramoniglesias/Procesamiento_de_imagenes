{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "haar_face_detection_2021_1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/joseramoniglesias/Procesamiento_de_imagenes/blob/master/haar_face_detection_2021_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVW15Fc13qGh"
      },
      "source": [
        "# OpenCV Face detection with Haar cascades"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMMXZuonJuo6"
      },
      "source": [
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jc_Lj0mcKGJJ"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfVsGRegJcq7"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/haar-face-detection/haar-face-detection.zip\n",
        "!unzip -qq haar-face-detection.zip\n",
        "%cd haar-face-detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQl-4t1OKQ3l"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vU6IIjjeKUdb"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9g021RoKQNW"
      },
      "source": [
        "# import the necessary packages\n",
        "from imutils.video import VideoStream\n",
        "import matplotlib.pyplot as plt\n",
        "import argparse\n",
        "import imutils\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAakXkQL5ate"
      },
      "source": [
        "### Function to display images in Jupyter Notebooks and Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2R7wEnD85YRd"
      },
      "source": [
        "def plt_imshow(title, image):\n",
        "    # convert the image frame BGR to RGB color space and display it\n",
        "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\tplt.imshow(image)\n",
        "\tplt.title(title)\n",
        "\tplt.grid(False)\n",
        "\tplt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wegd_Pv58Jby"
      },
      "source": [
        "### Implementing face detection with OpenCV and Haar Cascades"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Yk-lRE3Klu3"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-i\", \"--image\", type=str, required=True,\n",
        "#\thelp=\"path to input image\")\n",
        "#ap.add_argument(\"-c\", \"--cascade\", type=str,\n",
        "#\tdefault=\"haarcascade_frontalface_default.xml\",\n",
        "#\thelp=\"path to haar cascade face detector\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"image\": \"images/adrian_01.png\",\n",
        "    \"cascade\": \"haarcascade_frontalface_default.xml\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYAmnzMH5zXR"
      },
      "source": [
        "# load the haar cascade face detector from\n",
        "print(\"[INFO] loading face detector...\")\n",
        "detector = cv2.CascadeClassifier(args[\"cascade\"])\n",
        "\n",
        "# load the input image from disk, resize it, and convert it to\n",
        "# grayscale\n",
        "image = cv2.imread(args[\"image\"])\n",
        "image = imutils.resize(image, width=500)\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk5I4XJH5z_x"
      },
      "source": [
        "# detect faces in the input image using the haar cascade face\n",
        "# detector\n",
        "print(\"[INFO] performing face detection...\")\n",
        "rects = detector.detectMultiScale(gray, scaleFactor=1.05,\n",
        "\tminNeighbors=5, minSize=(30, 30),\n",
        "\tflags=cv2.CASCADE_SCALE_IMAGE)\n",
        "print(\"[INFO] {} faces detected...\".format(len(rects)))\n",
        "\n",
        "# loop over the bounding boxes\n",
        "for (x, y, w, h) in rects:\n",
        "\t# draw the face bounding box on the image\n",
        "\tcv2.rectangle(image, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "# show the output image\n",
        "plt_imshow(\"Image\", image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ouojbu08ZAD"
      },
      "source": [
        "### Implementing real-time face detection with Haar cascade"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9bLrSPfZ6lwC"
      },
      "source": [
        "# first, let's get a video on which we can run our face detector \n",
        "!wget https://colab-notebook-videos.s3-us-west-2.amazonaws.com/opencv_face_detection.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UeTwvm4OqHi"
      },
      "source": [
        "# construct the argument parser and parse the arguments\n",
        "#ap = argparse.ArgumentParser()\n",
        "#ap.add_argument(\"-c\", \"--cascade\", type=str,\n",
        "#\tdefault=\"haarcascade_frontalface_default.xml\",\n",
        "#\thelp=\"path to haar cascade face detector\")\n",
        "#args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "    \"input\": \"opencv_face_detection.mp4\",\n",
        "    \"output\": \"output.avi\",\n",
        "    \"cascade\": \"haarcascade_frontalface_default.xml\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODmsWpXS6n4Y"
      },
      "source": [
        "# load the haar cascade face detector from\n",
        "print(\"[INFO] loading face detector...\")\n",
        "detector = cv2.CascadeClassifier(args[\"cascade\"])\n",
        "\n",
        "# grab a reference to the video file and initialize pointer to output\n",
        "# video file\n",
        "print(\"[INFO] opening video file...\")\n",
        "vs = cv2.VideoCapture(args[\"input\"])\n",
        "writer = None"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYh9WHYr6sXT"
      },
      "source": [
        "# loop over the frames from the video stream\n",
        "while True:\n",
        "\t# grab the next frame\n",
        "\tframe = vs.read()[1]\n",
        "\n",
        "\t# if we did not grab a frame then we have reached the end of the\n",
        "\t# video\n",
        "\tif frame is None:\n",
        "\t\tbreak\n",
        "    \n",
        "    # resize the frame and convert it to grayscale\n",
        "\tframe = imutils.resize(frame, width=500)\n",
        "\tgray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "\t# perform face detection\n",
        "\trects = detector.detectMultiScale(gray, scaleFactor=1.05,\n",
        "\t\tminNeighbors=5, minSize=(30, 30),\n",
        "\t\tflags=cv2.CASCADE_SCALE_IMAGE)\n",
        " \n",
        "\n",
        "\t# loop over the bounding boxes\n",
        "\tfor (x, y, w, h) in rects:\n",
        "\t\t# draw the face bounding box on the image\n",
        "\t\tcv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "\t# if the video writer is None *AND* we are supposed to write\n",
        "\t# the output video to disk initialize the writer\n",
        "\tif writer is None and args[\"output\"] is not None:\n",
        "\t\tfourcc = cv2.VideoWriter_fourcc(*\"MJPG\")\n",
        "\t\twriter = cv2.VideoWriter(args[\"output\"], fourcc, 20,\n",
        "\t\t\t(frame.shape[1], frame.shape[0]), True)\n",
        "  \n",
        "\t# if the writer is not None, write the frame to disk\n",
        "\tif writer is not None:\n",
        "\t\twriter.write(frame)\n",
        "\n",
        "# do a bit of cleanup\n",
        "vs.release()\n",
        "\n",
        "# check to see if the video writer point needs to be released\n",
        "if writer is not None:\n",
        "\twriter.release()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpSXMhHhHOJw"
      },
      "source": [
        "Note that the above code block may take time to execute. If you are interested to view the video within Colab just execute the following code blocks. Note that it may be time-consuming.\n",
        "\n",
        "Our output video is produced in `.avi` format. First, we need to convert it to `.mp4` format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhYbtMwnHTp-"
      },
      "source": [
        "!ffmpeg -i output.avi output.mp4"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab": {
          "background_save": true
        },
        "id": "UJCPzNUbHk8n"
      },
      "source": [
        "#@title Display video inline\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open(\"output.mp4\", \"rb\").read()\n",
        "dataURL = \"data:video/mp4;base64,\" + b64encode(mp4).decode()\n",
        "HTML(\"\"\"\n",
        "<video width=400 controls>\n",
        "      <source src=\"%s\" type=\"video/mp4\">\n",
        "</video>\n",
        "\"\"\" % dataURL)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}